apiVersion: v1
kind: Pod
metadata:
  name: ml-in-prod-inference
spec:
  containers:
  - name: inference
    image: k8s.gcr.io/busybox
    ports:
    - containerPort: 80
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"
